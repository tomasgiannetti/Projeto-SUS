{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70cd919",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T14:26:54.669882Z",
     "start_time": "2022-12-15T14:26:47.033331Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4a52a9",
   "metadata": {},
   "source": [
    "# Transformando os arquivos dbf em csv, unificando os arquivos por ano e criando novos csv para posterior analise no Tableau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee3d57d",
   "metadata": {},
   "source": [
    "O SUS disponibiliza os arquivos no formato `dbc` no site: https://datasus.saude.gov.br/transferencia-de-arquivos/ ao clicar em: \n",
    "\n",
    "SIM - Sistema de Informação de Mortalidade -> Dados -> DO - Declarações de Óbito - 1979 a 2021 -> Selecionar Ano desejado -> Selecionar estados -> Download -> arquivo.zip. \n",
    "\n",
    "Esse arquivo foi extraido e transformado em `dbf` utilizando o `Tabwin`, e posteriormente tratado aqui no python para transformação em `csv` para leitura no pandas e outras manipulações de dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd1a3d5",
   "metadata": {},
   "source": [
    "Criando uma lista com nomes e paths dos arquivos para facilitar a transformação via loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3e7e1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-13T17:10:50.067069Z",
     "start_time": "2022-12-13T17:10:50.045068Z"
    }
   },
   "outputs": [],
   "source": [
    "estados = sorted([\"data/IBGE MORTALIDADE/todos/DOAC\",\"data/IBGE MORTALIDADE/todos/DOAL\",\"data/IBGE MORTALIDADE/todos/DOAM\",\"data/IBGE MORTALIDADE/todos/DOAP\",\"data/IBGE MORTALIDADE/todos/DOBA\",\"data/IBGE MORTALIDADE/todos/DOBR\",\"data/IBGE MORTALIDADE/todos/DOCE\",\"data/IBGE MORTALIDADE/todos/DODF\",\"data/IBGE MORTALIDADE/todos/DOES\",\"data/IBGE MORTALIDADE/todos/DOGO\",\"data/IBGE MORTALIDADE/todos/DOMA\",\"data/IBGE MORTALIDADE/todos/DOMG\",\"data/IBGE MORTALIDADE/todos/DOMS\",\"data/IBGE MORTALIDADE/todos/DOMT\",\"data/IBGE MORTALIDADE/todos/DOPA\",\"data/IBGE MORTALIDADE/todos/DOPB\",\"data/IBGE MORTALIDADE/todos/DOPE\",\"data/IBGE MORTALIDADE/todos/DOPI\",\"data/IBGE MORTALIDADE/todos/DOPR\",\"data/IBGE MORTALIDADE/todos/DORJ\",\"data/IBGE MORTALIDADE/todos/DORN\",\"data/IBGE MORTALIDADE/todos/DORO\",\"data/IBGE MORTALIDADE/todos/DORR\",\"data/IBGE MORTALIDADE/todos/DORS\",\"data/IBGE MORTALIDADE/todos/DOSC\",\"data/IBGE MORTALIDADE/todos/DOSE\",\"data/IBGE MORTALIDADE/todos/DOSP\",\"data/IBGE MORTALIDADE/todos/DOTO\"]*21)\n",
    "#[[x,estados.count(x)] for x in set(estados)] #formula usada para verificar a quantidade e o que está na lista\n",
    "anos = list(range(2000,2021))\n",
    "anos = [str(x) for x in anos]\n",
    "anos = [x+'.dbf' for x in anos]*28 # 28 pois existem 28 arquivos diferentes (existe um para Brasilia também)\n",
    "arquivo = [x + y for x, y in zip(estados, anos)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71742365",
   "metadata": {},
   "source": [
    "   Para transformar `dbf` em `csv`, primeiramente criei uma função usando a biblioteca `dbfpy`, utilizando a `dbf.Table` e `dbf.export`.\n",
    "   \n",
    "   O resultado foi satisfatório com alguns erros de codec já que os arquivos antes de 2018 são transformados usando o ascii e depois de 2018 são transformados usando o `asciii` (no caso do uso da dbfpy).\n",
    "   \n",
    "   Como a ideia desse projeto é de utilizar vários anos para a analise de uma forma mais pratica após mais pesquisa verifiquei que a função encontrada no link https://blog.finxter.com/how-to-convert-a-dbf-to-a-csv-in-python/ realiza a conversão sem usar a `dbfpy`. Por isso optei pelo uso da mesma (apesar que ligeiramente alterada), que não gerou erro na transformação, já que ele usa a biblioteca `dbfread` para ler o `dbf` e a biblioteca csv para converter arquivo lido no python do arquivo dbf em strings separadas por virgulas (arquivo csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d263d5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-13T15:13:41.365311Z",
     "start_time": "2022-12-13T13:49:50.605226Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from dbfread import DBF\n",
    "def dbf_to_csv(path):\n",
    "    '''Converting the .dbf at the specified path and\n",
    "       returns the name of the .csv file after conversion.\n",
    "       The .csv file has same path and naming scheme. \n",
    "       Examples:\n",
    "       (1) my_file.dbf --> my_file.csv\n",
    "       (2) /path/to/file/my_file.dbf --> /path/to/file/my_file.csv\n",
    "    '''\n",
    "    # Set the name of the CSV file\n",
    "    for path in arquivo:\n",
    "        try:\n",
    "            csv_path = path[:-4] + \".csv\"\n",
    "            # Create a DBF object, i.e., load the .dbf file into the code \n",
    "            dbf = DBF(path)\n",
    "            # Create a CSV file and fill it with dbf data\n",
    "            with open(csv_path, 'w', newline = '') as f:\n",
    "                # Create the CSV writer\n",
    "                writer = csv.writer(f)\n",
    "                # Write the CSV column names\n",
    "                writer.writerow(dbf.field_names)\n",
    "                # Write the CSV rows\n",
    "                for record in dbf:\n",
    "                    writer.writerow(list(record.values()))\n",
    "        except Exception as e:\n",
    "            print(path)\n",
    "            print(e)\n",
    "            pass\n",
    "    return csv_path\n",
    "dbf_to_csv(arquivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e466ff2",
   "metadata": {},
   "source": [
    "Após analise preliminar dos bancos de dados, foi executada a concatenação dos bancos de dados por ano, para posterior analise no Tableau.\n",
    "Para diminuição do tamanho do arquivo e efeitos de analise, foram selecionadas colunas especificas no `pd.concat` em que o número de nulos é baixo e também são relevantes para a analise, colunas duplicadas foram dropadas e depois transformados em `.csv`. A celula abaixo foi utilizada para os anos de 2014 a 2020, que contem as mesmas colunas em todos os estados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3068ebf6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-13T19:15:42.103640Z",
     "start_time": "2022-12-13T19:14:50.273098Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "ano = '2020'\n",
    "csvs = [pd.read_csv(f'data/IBGE MORTALIDADE/todos/{arquivo}',usecols=['ORIGEM','DIFDATA','STDONOVA','STDOEPIDEM','DTRECORIGA','ATESTADO','CODIFICADO','TIPOBITO','DTCADASTRO','CODMUNOCOR','LOCOCOR','CODMUNRES','CONTADOR','IDADE','SEXO','CAUSABAS','DTOBITO','NUMEROLOTE','STCODIFICA','VERSAOSCB','DTRECEBIM','CAUSABAS_O','DTNASC','DTATESTADO','HORAOBITO','LINHAA','NATURAL','CODMUNNATU','RACACOR','ESTCIV','ESC','ESCFALAGR1','ESC2010']) for arquivo in os.listdir(r'data/IBGE MORTALIDADE/todos') if arquivo.endswith(f\"{ano}.csv\")]\n",
    "csvs = pd.concat(csvs)\n",
    "csvs.drop_duplicates(inplace=True) #dropando possiveis linhas duplicadas nos datasets\n",
    "csvs.to_csv(f\"data/IBGE MORTALIDADE/csvs{ano}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ccaba3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T14:27:22.522404Z",
     "start_time": "2022-12-15T14:26:54.693882Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "municipios = pd.read_excel(r'data\\MUNICIPIOS IBGE\\RELATORIO_DTB_BRASIL_MUNICIPIO.xls')\n",
    "df = pd.read_csv(r'data/IBGE MORTALIDADE/csvs2020.CSV')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165173b5",
   "metadata": {},
   "source": [
    "Os campos de localidade estão preenchidos como codigo do IBGE, por isso foi feito o download da planilha de municipios e a adição dos nomes de municipios para as informações das colunas `'CODMUNOCOR'`, `'CODMUNNATU'` e `'CODMUNRES'`. As novas colunas foram posteriormente renomeadas e tratadas para refletir a informação de forma correta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd7b1cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-14T20:59:17.269099Z",
     "start_time": "2022-12-14T20:58:36.525100Z"
    }
   },
   "outputs": [],
   "source": [
    "municipios['Código Município Completo'] = municipios['Código Município Completo'].astype('str').str[:-1].astype('float')\n",
    "#merge por CODMUNOCOR\n",
    "df['CODMUNOCOR'] = df['CODMUNOCOR'].astype('float')\n",
    "df = df.merge(municipios[['Código Município Completo','Nome_Município','Nome_UF']],left_on='CODMUNOCOR',right_on='Código Município Completo')\n",
    "df.drop(columns='Código Município Completo',inplace=True)\n",
    "df.rename(columns = {'Nome_Município' : 'MUNICIPIO_OCOR','Nome_UF':'UF_OCOR'},inplace=True)\n",
    "df['MUNICIPIO_OCOR'] != df['MUNICIPIO_OCOR']\n",
    "#merge por CODMUNNATU\n",
    "df['CODMUNNATU'] = df['CODMUNNATU'].astype('float')\n",
    "df = df.merge(municipios[['Código Município Completo','Nome_Município','Nome_UF']],left_on='CODMUNNATU',right_on='Código Município Completo',how='left')\n",
    "df.drop(columns='Código Município Completo',inplace=True)\n",
    "df.rename(columns = {'Nome_Município' : 'MUNICIPIO_NATU','Nome_UF':'UF_NATU'},inplace=True)\n",
    "df.loc[df['MUNICIPIO_NATU'].isnull(),'MUNICIPIO_NATU'] = 'Estrangeiro'\n",
    "df.loc[df['UF_NATU'].isnull(),'UF_NATU'] = 'Estrangeiro'\n",
    "#merge por CODMUNRES\n",
    "df['CODMUNRES'] = df['CODMUNRES'].astype('float')\n",
    "df = df.merge(municipios[['Código Município Completo','Nome_Município','Nome_UF']],left_on='CODMUNRES',right_on='Código Município Completo',how='left')\n",
    "df.drop(columns='Código Município Completo',inplace=True)\n",
    "df.rename(columns = {'Nome_Município' : 'MUNICIPIO_RES','Nome_UF':'UF_RES'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2798280",
   "metadata": {},
   "source": [
    "Foi descoberta a necessidade de criar novas planilhas `'.csv'` para integração com planilhas de CID existentes no SUS no `Tableau` ou `SQL`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16036c03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-14T21:00:08.199616Z",
     "start_time": "2022-12-14T20:59:49.853616Z"
    }
   },
   "outputs": [],
   "source": [
    "#Tratando e criando um novo arquivo para posterior adição ao Tableau, para analisar os CID'S individualmente\n",
    "df['ATESTADO'] = df['ATESTADO'].str.findall('[a-zA-Z]+\\d+') #separando os cids do atestado em lista dentro da coluna\n",
    "df['LINHAA'] = df['LINHAA'].str.findall('[a-zA-Z]+\\d+')\n",
    "\n",
    "ano = '2020'\n",
    "dfcont = df[['CONTADOR','ATESTADO']]\n",
    "dfcont = dfcont.explode('ATESTADO')\n",
    "dfcont.to_csv(f'data/IBGE MORTALIDADE/dfcont{ano}.csv')\n",
    "\n",
    "dfcont = df[['CONTADOR','LINHAA']] \n",
    "dfcont = dfcont.explode('LINHAA')\n",
    "dfcont.to_csv(f'data/IBGE MORTALIDADE/dflinhaa{ano}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13895a4",
   "metadata": {},
   "source": [
    "# Tratamento de Nulos e necessidade de colunas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e354884",
   "metadata": {},
   "source": [
    "Esse tratamento é feito por base de analise da quantidade de nulos em cada coluna no dataset original sem retirada de colunas. Também é feita a analise subjetiva de quais colunas são necessárias para a analise, sendo que as irrelevantes são retiradas do dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab16a19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-14T20:59:24.955618Z",
     "start_time": "2022-12-14T20:59:17.271101Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(data=((df.isnull().sum())/(df.shape[0])).sort_values().head(44)).reset_index() #vendo a % de nulos nas colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b02cdc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-14T20:59:32.609618Z",
     "start_time": "2022-12-14T20:59:24.958617Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(data=((df.isnull().sum())/(df.shape[0])).sort_values().tail(44)).reset_index()\n",
    "#vendo a % de nulos nas colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50cd89f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-14T20:59:49.851617Z",
     "start_time": "2022-12-14T20:59:32.612618Z"
    }
   },
   "outputs": [],
   "source": [
    "#colunas_nona = list(pd.DataFrame(data=((df.isnull().sum())/(df.shape[0])).sort_values().head(44)).reset_index()['index'])[:40]\n",
    "colunas_nona = ['DIFDATA','STDOEPIDEM','ATESTADO','CODIFICADO','DTCADASTRO','CODMUNOCOR','LOCOCOR','CODMUNRES','CONTADOR','IDADE','SEXO','CAUSABAS','DTOBITO','CAUSABAS_O','DTNASC','DTATESTADO','HORAOBITO','LINHAA','NATURAL','CODMUNNATU','RACACOR','ESTCIV','ESC','ESCFALAGR1','ESC2010','MUNICIPIO_OCOR','UF_OCOR','MUNICIPIO_NATU','UF_NATU','MUNICIPIO_RES','UF_RES']\n",
    "#colocando o nome das colunas para efeito de tratamento em outros arquivos, para sempre manter as mesmas colunas e reportar erro em caso de colunas distintas\n",
    "df = df[colunas_nona] #dropando colunas com muitos nulos\n",
    "df.drop_duplicates(inplace=True) #dropando possiveis linhas duplicadas nos datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08b2fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ano = '2020'\n",
    "dfcont = df[['CONTADOR','LINHAA']] \n",
    "dfcont = dfcont.explode('LINHAA')\n",
    "dfcont.to_csv(f'data/IBGE MORTALIDADE/dflinhaa{ano}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4371e2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-14T21:00:11.750616Z",
     "start_time": "2022-12-14T21:00:08.201618Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(data=((df.isnull().sum())/(df.shape[0])).sort_values()).reset_index()\n",
    "#verificando novamente os nulos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eaa5d23",
   "metadata": {},
   "source": [
    "# Tratanto coluna de data de obitos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2c1584",
   "metadata": {},
   "source": [
    "Para tratar a coluna de data de obitos, é necessário usar o pd.to_datetime, mas essa função não da certo pois algumas datas não tem a mesma quantidade de caracteres que outras (as datas de 1 a 10 não tem o zero na frente), por isso precisamos adicionar o zero na frete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec971e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-14T21:00:13.986617Z",
     "start_time": "2022-12-14T21:00:11.752618Z"
    }
   },
   "outputs": [],
   "source": [
    "df['DTOBITO'] = df['DTOBITO'].astype('str')\n",
    "df['DTOBITO'] = df['DTOBITO'].str.zfill(8)\n",
    "df['DTOBITO'] = pd.to_datetime(df['DTOBITO'],format='%d%m%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491f02ca",
   "metadata": {},
   "source": [
    "# Padronizando a coluna de hora de obito"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618feabe",
   "metadata": {},
   "source": [
    "Nesse caso a hora de óbito possuia valores nulos, como isso não afeta a analise proposta, a linha será mantida e o tratamento será feito somente nas linhas que não possuem valor nulo, para ficar no formato hh:mm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7015fc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-14T21:00:20.188616Z",
     "start_time": "2022-12-14T21:00:13.988617Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[~df['HORAOBITO'].isnull(),'HORAOBITO'] = df['HORAOBITO'].astype('str').str.strip('0').str.strip('.').str.zfill(4)\n",
    "df['HORAOBITO'] = (df['HORAOBITO'].str[:2]+':'+df['HORAOBITO'].str[2:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bb65f6",
   "metadata": {},
   "source": [
    "# Tratando a coluna Natural"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5775bf03",
   "metadata": {},
   "source": [
    "Essa coluna fala da naturalidade, em que as que começam com 8 são do brasil e as outras são de estrangeiros. Como não precisamos saber de qual pais os estrangeiros vem, todos serão substituidos por 0 (novo codigo para estrangeiros)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acf99cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-14T21:00:25.342616Z",
     "start_time": "2022-12-14T21:00:20.194618Z"
    }
   },
   "outputs": [],
   "source": [
    "df['NATURAL'] = df['NATURAL'].astype('str')\n",
    "df['NATURAL'] = df['NATURAL'].str.replace('nan','0')\n",
    "estrangeiros = (~df['NATURAL'].str.startswith('8')&~df['NATURAL'].str.startswith('0'))\n",
    "df['NATURAL'][estrangeiros] = '0'\n",
    "df['NATURAL'] = df['NATURAL'].astype('float').astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c697a4b8",
   "metadata": {},
   "source": [
    "# Tratando a coluna DTNASC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f370a2ee",
   "metadata": {},
   "source": [
    "Devemos tratar e transformar para datetime, mas podemos ver que a coluna tem vários nulos e, que quando nessa coluna o valor é nulo, a maioria das outras colunas na mesma linha também ficam como nulos, por esse motivo foi decidido que as linhas com nulo na data de nascimento serão dropadas.\n",
    "\n",
    "O tratamento que foi necessário após a exclusão foi retirar o .0 do float, acrescentar o 0 no primeiro digito das strings que continham menos de 8 caracteres (mesmo tratamento da ultima coluna de data) e passar para datetime com o pd.to_datetime.\n",
    "\n",
    "Foram descobertos erros de digitação nessa coluna, por isso no pd.to_datetime foi necessário entrar com o argumento coerce, para rodar a função mesmo com esses erros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89da4434",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-14T21:00:26.741617Z",
     "start_time": "2022-12-14T21:00:25.345618Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[~df['DTNASC'].isna()] #Removendo as linhas com nulos na coluna data de nascimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106590fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-14T21:00:34.948617Z",
     "start_time": "2022-12-14T21:00:26.743617Z"
    }
   },
   "outputs": [],
   "source": [
    "df['DTNASC'] = df['DTNASC'].astype('int').astype('str').str.zfill(8)\n",
    "df['DTNASC'] = pd.to_datetime(df['DTNASC'], format='%d%m%Y',errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d695b0e3",
   "metadata": {},
   "source": [
    "# Tratando coluna IDADE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427c098c",
   "metadata": {},
   "source": [
    "Essa coluna está preenchida por codigos conforme abaixo:\n",
    "\n",
    "Idade, composto de dois subcampos. O primeiro, de 1 dígito, indica a unidade da idade, conforme a tabela a seguir. O segundo, de dois dígitos, indica a quantidade de unidades:\n",
    "\n",
    "0: Idade ignorada, o segundo subcampo e\n",
    "\n",
    "1: Horas, o segundo subcampo varia de 01 a 23\n",
    "\n",
    "2: Dias, o segundo subcampo varia de 01 a 29\n",
    "\n",
    "3: Meses, o segundo subcampo varia de 01 a 11\n",
    "\n",
    "4: Anos, o segundo subcampo varia de 00 a 99\n",
    "\n",
    "5: Anos (mais de 100 anos), o segundo subcampo varia de 0 a 99,Exemplos:\n",
    "\n",
    "000: Idade ignorada\n",
    "\n",
    "020: 20 minutos\n",
    "\n",
    "103: 3 horas\n",
    "\n",
    "204: 4 dias\n",
    "\n",
    "305: 5 meses\n",
    "\n",
    "400: menor de 1 ano, mas não se sabe o numero de horas, dias ou meses\n",
    "\n",
    "410: 10 anos\n",
    "\n",
    "505: 105 anos \n",
    "\n",
    "A idade será alterada para a idade correta em anos, no caso de menor que 1 ano será ajustada para 'menor 1'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ac38c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-14T21:00:46.925617Z",
     "start_time": "2022-12-14T21:00:34.950617Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[df['IDADE'].astype('str').str.startswith('1'),'IDADECORRIGIDA'] = 0\n",
    "df.loc[df['IDADE'].astype('str').str.startswith('2'),'IDADECORRIGIDA'] = 0\n",
    "df.loc[df['IDADE'].astype('str').str.startswith('3'),'IDADECORRIGIDA'] = 0\n",
    "df.loc[df['IDADE'].astype('str').str.startswith('4'),'IDADECORRIGIDA'] = df['IDADE'].astype('str').str[1:]\n",
    "df.loc[df['IDADE'].astype('str').str.startswith('5'),'IDADECORRIGIDA'] = ('1'+ df['IDADE'].astype('str').str[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f73484b",
   "metadata": {},
   "source": [
    "# Tratando outras colunas de Datas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573be349",
   "metadata": {},
   "source": [
    "No caso do tratamento de outras colunas de data, foi feito o mesmo tratamento da coluna `DTNASC`, para as colunas `DTATESTADO` e `DTCADASTRO`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d28c2a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-14T21:02:29.943617Z",
     "start_time": "2022-12-14T21:02:27.464617Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[~df['DTATESTADO'].isna(),'DTATESTADO'] = df['DTATESTADO'].astype('str').str.zfill(10).str[:-2]\n",
    "df['DTATESTADO'] = pd.to_datetime(df['DTATESTADO'], format='%d%m%Y',errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61c90ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-14T21:03:23.320618Z",
     "start_time": "2022-12-14T21:03:19.484616Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[~df['DTCADASTRO'].isna(),'DTCADASTRO'] = df['DTCADASTRO'].astype('str').str.zfill(10).str[:-2]\n",
    "df['DTCADASTRO'] = pd.to_datetime(df['DTCADASTRO'], format='%d%m%Y',errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a42b03a",
   "metadata": {},
   "source": [
    "# Criando um arquivo csv com o tratamento concluído"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d67d941",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-14T21:06:55.187136Z",
     "start_time": "2022-12-14T21:05:04.171134Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('data/IBGE MORTALIDADE/dftratado2020.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "531.844px",
    "left": "948px",
    "right": "20px",
    "top": "150px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
